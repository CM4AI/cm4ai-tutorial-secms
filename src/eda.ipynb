{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2190267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d2651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"../data/raw\"\n",
    "data_sets = [p.name for p in Path(base_path).iterdir() if p.is_dir()]\n",
    "\n",
    "filename_pattern = r\"[_-](?P<category>[A-Za-z]+)_(?P<expnum>\\d+)_Report\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d50cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_input_labels(df_raw):\n",
    "    cols = df_raw.columns.astype(str).tolist()\n",
    "    cols = [re.sub(r\"^PG\\.\", \"\", c) for c in cols]\n",
    "    biosep_cols = [c for c in cols if \"biosep\" in c.lower()]\n",
    "    rename_map = {c: f\"biosep_{i+1}_quantity\" for i, c in enumerate(biosep_cols)}\n",
    "    cols = [rename_map.get(c, c) for c in cols]\n",
    "    df_raw.columns = cols\n",
    "    return df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de63732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _n_total_unique(s: pd.Series) -> tuple[int, int]:\n",
    "    return len(s), s.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ca3313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_secms_report(df: pd.DataFrame, df_ambig: pd.DataFrame | None = None) -> None:\n",
    "    COL_UNIPROT = \"UniProtIds\"\n",
    "    COL_CELL    = \"cell_line\"\n",
    "    COL_CAT     = \"category\"\n",
    "    COL_REP     = \"expnum\"\n",
    "\n",
    "    ambig_by_cell_cat_rep = {}\n",
    "    ambig_by_rep = {}\n",
    "\n",
    "    if df_ambig is not None and len(df_ambig) > 0:\n",
    "        if all(c in df_ambig.columns for c in [COL_CELL, COL_CAT, COL_REP]):\n",
    "            ambig_by_cell_cat_rep = (\n",
    "                df_ambig.groupby([COL_CELL, COL_CAT, COL_REP], dropna=False)\n",
    "                        .size()\n",
    "                        .to_dict()\n",
    "            )\n",
    "        elif COL_REP in df_ambig.columns:\n",
    "            # fallback if ambig df doesn't have cell_line/category\n",
    "            ambig_by_rep = (\n",
    "                df_ambig.groupby(COL_REP, dropna=False)\n",
    "                        .size()\n",
    "                        .to_dict()\n",
    "            )\n",
    "\n",
    "    # --- overall ---\n",
    "    total, unique = _n_total_unique(df[COL_UNIPROT])\n",
    "    cell_lines = sorted(df[COL_CELL].dropna().unique())\n",
    "    n_cell_lines = len(cell_lines)\n",
    "\n",
    "    print(\"=== Overall ===\")\n",
    "    print(f\"Cell lines:           {n_cell_lines:,}\")\n",
    "    print(f\"Cell line list:       {', '.join(cell_lines)}\")\n",
    "    print(f\"Total UniProtIds rows: {total:,}\")\n",
    "    print(f\"Unique UniProtIds:     {unique:,}\")\n",
    "    print(f\"Total ambiguous rows: {len(df_ambig):,}\")\n",
    "    print()\n",
    "\n",
    "    # --- per cell line ---\n",
    "    for cell_line, dcell in df.groupby(COL_CELL, dropna=False, sort=True):\n",
    "        n_cats = dcell[COL_CAT].nunique(dropna=True)\n",
    "        t_cell, u_cell = _n_total_unique(dcell[COL_UNIPROT])\n",
    "\n",
    "        print(f\"=== Cell line: {cell_line} ===\")\n",
    "        print(f\"Categories: {n_cats:,}\")\n",
    "        print(f\"Total UniProtIds rows: {t_cell:,}\")\n",
    "        print(f\"Unique UniProtIds:     {u_cell:,}\")\n",
    "        print()\n",
    "\n",
    "        # --- per category (within cell line) ---\n",
    "        for cat, dcat in dcell.groupby(COL_CAT, dropna=False, sort=True):\n",
    "            t_cat, u_cat = _n_total_unique(dcat[COL_UNIPROT])\n",
    "            n_reps_cat = dcat[COL_REP].nunique(dropna=True)\n",
    "\n",
    "            print(f\"  - Category: {cat}\")\n",
    "            print(f\"    Total UniProtIds rows: {t_cat:,}\")\n",
    "            print(f\"    Unique UniProtIds:     {u_cat:,}\")\n",
    "            print(f\"    Replicas: {n_reps_cat:,}\")\n",
    "\n",
    "            # --- per replicate (within category) ---\n",
    "            for rep, drep in dcat.groupby(COL_REP, dropna=False, sort=True):\n",
    "                if df_ambig is None:\n",
    "                    ambig_rep = \"UNKNOWN\"\n",
    "                else:\n",
    "                    ambig_rep = ambig_by_cell_cat_rep.get((cell_line, cat, rep), None)\n",
    "                    if ambig_rep is None:\n",
    "                        ambig_rep = ambig_by_rep.get(rep, \"UNKNOWN\")\n",
    "\n",
    "                t_rep, u_rep = _n_total_unique(drep[COL_UNIPROT])\n",
    "                print(f\"      * Replica {rep} UniProtIds: total {t_rep:,} (unique {u_rep:,})\")\n",
    "                print(f\"         * Ambiguous rows: {ambig_rep}\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5933658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for data_set in data_sets:\n",
    "    data_path = os.path.join(base_path, data_set)\n",
    "    cell_line = data_set.split(\"_\")[-1]\n",
    "\n",
    "    data_files = glob.glob(os.path.join(data_path, '*.tsv'))\n",
    "\n",
    "    for data_file in data_files:\n",
    "        filename = Path(data_file).stem\n",
    "        m = re.search(filename_pattern, filename)\n",
    "\n",
    "        category = None\n",
    "        expnum = None\n",
    "        if m:\n",
    "            category = m.group(\"category\")\n",
    "            expnum = int(m.group(\"expnum\"))\n",
    "\n",
    "        df = pd.read_csv(data_file, sep=\"\\t\")\n",
    "        df = clean_input_labels(df)\n",
    "        df[\"category\"] = category\n",
    "        df[\"expnum\"] = expnum\n",
    "        df[\"cell_line\"] = cell_line\n",
    "        df[\"source_file\"] = data_file\n",
    "\n",
    "        dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751f2432",
   "metadata": {},
   "outputs": [],
   "source": [
    "secms_data = pd.concat(dfs, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233cd6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with ambiguous gene/protein identification\n",
    "ambig_mask = (\n",
    "        secms_data[\"Genes\"].str.contains(\";\", na=False) |\n",
    "        secms_data[\"ProteinAccessions\"].str.contains(\";\", na=False) |\n",
    "        secms_data[\"ProteinNames\"].str.contains(\";\", na=False)  \n",
    "    )\n",
    "\n",
    "secms_data_clean = secms_data.loc[~ambig_mask]\n",
    "secms_data_ambig = secms_data.loc[ambig_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d945028d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_secms_report(secms_data_clean, secms_data_ambig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eeadf69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cm4ai-tutorial-secms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
